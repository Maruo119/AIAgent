import os
import json
import subprocess
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI()

# =========================
# ğŸ›  ãƒ„ãƒ¼ãƒ«
# =========================

def read_file(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def write_file(path, content):
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return "File written successfully."

def run_tests():
    result = subprocess.run(
        ["python", "-m", "pytest"],
        capture_output=True,
        text=True
    )
    return result.stdout + result.stderr

# =========================
# ğŸ“¦ ãƒ„ãƒ¼ãƒ«å®šç¾©
# =========================

tools = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "parameters": {
                "type": "object",
                "properties": {"path": {"type": "string"}},
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string"},
                    "content": {"type": "string"}
                },
                "required": ["path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "run_tests",
            "parameters": {
                "type": "object",
                "properties": {}
            }
        }
    }
]

# =========================
# åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# =========================

issue_text = read_file("issue.txt")

messages = [
    {"role": "system", "content": "ã‚ãªãŸã¯Issueã‚’è§£æ±ºã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚"},
    {"role": "user", "content": f"""
Issue:
{issue_text}

å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã¯ target_code.py ã§ã™ã€‚
ãƒ†ã‚¹ãƒˆãŒé€šã‚‹ã¾ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
"""}
]

# =========================
# ğŸ” æœ€å¤§3ã‚¹ãƒ†ãƒƒãƒ—
# =========================

for step in range(3):

    print(f"\n===== STEP {step+1} =====")

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )

    message = response.choices[0].message

    if not message.tool_calls:
        print("LLMãŒãƒ„ãƒ¼ãƒ«ã‚’é¸ã³ã¾ã›ã‚“ã§ã—ãŸ")
        break

    tool_call = message.tool_calls[0]
    tool_name = tool_call.function.name
    arguments = json.loads(tool_call.function.arguments or "{}")

    print("ğŸ§  é¸æŠ:", tool_name)

    # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ
    if tool_name == "read_file":
        result = read_file(arguments["path"])
    elif tool_name == "write_file":
        result = write_file(arguments["path"], arguments["content"])
    elif tool_name == "run_tests":
        result = run_tests()
    else:
        result = "Unknown tool"

    print("ğŸ›  çµæœ:", result[:500])

    # LLMã«çµæœã‚’æ¸¡ã™
    messages.append(message)
    messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "content": result
    })

    # ãƒ†ã‚¹ãƒˆæˆåŠŸãªã‚‰çµ‚äº†
    if tool_name == "run_tests" and "failed" not in result.lower():
        print("ğŸ‰ ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
        break
